{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ehuntley/Desktop/duspviz/spatial-data-science/python-bs/.venv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind webscraping is this: gather data quickly and replicably from websites by taking advantage of the fact that web pages are structured documents. While they are individually idiosyncratic, they tend to be _internally consistent_. This means that web scraping is always a bespoke affair---you can't build a web scraper that will simply work in a generalizable way for all pages. However, there _are_ general principles that, when rehearsed, will allow you to develop a scraper for a given website without too much effort.\n",
    "\n",
    "The scraper we're going to build today downloads key information about DUSP faculty from the [DUSP website's 'people' list](http://dusp.mit.edu/people). We're going to scrape information about affiliation, navigate through weblinks, and download photos. Along the way, we'll be doing some neat tricks---naming downloaded photos such that their nomenclature is consistent and dealing with missing and inaccessible information.\n",
    "\n",
    "To do this, we'll be using a couple of Python packages. The first is `bs4`, or Beautiful Soup 4. This is an HTML and XML parser which takes a downloaded web page and gives us objects and methods for navigating its structure inuititively. It's a very, very standard tool for use in web scraping applications. We'll also be using `wget` to download files, and `requests` to request webpages.\n",
    "\n",
    "As such, the first thing you'll need to do is install these packages. Assuming you've created and activated your virtual environment, you'll want to install these packages using `pip`.\n",
    "\n",
    "```sh\n",
    "pip install requests wget bs4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://dusp.mit.edu/people'\n",
    "base_page = requests.get(base_url)\n",
    "soup = BeautifulSoup(base_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"views-row views-row-1 views-row-odd views-row-first row-disc-IDG row-people\">\n",
      "<div> <span><div class=\"bull\"></div></span> </div>\n",
      "<div class=\"views-field views-field-field-user-picture\"> <div class=\"field-content\"><img alt=\"\" src=\"http://dusp.mit.edu/sites/dusp.mit.edu/files/styles/profile_pic/public/user/pictures/cherie.jpg?itok=tqCmbLrz\"/></div> </div>\n",
      "<div class=\"views-field views-field-name\"> <span class=\"field-content\"><a class=\"username\" href=\"/faculty/cherie-abbanat\" title=\"View user profile.\">Cherie Abbanat</a></span> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-1\"> <div class=\"field-content\">Lecturer of International Development and Urban Studies</div> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-2\"> <div class=\"field-content\"></div> </div>\n",
      "<div class=\"views-field views-field-field-other-division\"> <div class=\"field-content\"></div> </div> </div>,\n",
      " <div class=\"views-row views-row-2 views-row-even row-disc-IDG row-people\">\n",
      "<div> <span><div class=\"bull\"></div></span> </div>\n",
      "<div class=\"views-field views-field-field-user-picture\"> <div class=\"field-content\"><img alt=\"\" src=\"http://dusp.mit.edu/sites/dusp.mit.edu/files/styles/profile_pic/public/user/pictures/Amb-altidor2018a-e1541541394781_1.jpg?itok=gF_9ihBx\"/></div> </div>\n",
      "<div class=\"views-field views-field-name\"> <span class=\"field-content\"><a class=\"username\" href=\"/faculty/paul-altidor\" title=\"View user profile.\">Paul Altidor</a></span> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-1\"> <div class=\"field-content\">Visiting Lecturer of International Development and Planning </div> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-2\"> <div class=\"field-content\"></div> </div>\n",
      "<div class=\"views-field views-field-field-other-division\"> <div class=\"field-content\"></div> </div> </div>,\n",
      " <div class=\"views-row views-row-3 views-row-odd row-disc-EPP row-people\">\n",
      "<div> <span><div class=\"bull\"></div></span> </div>\n",
      "<div class=\"views-field views-field-field-user-picture\"> <div class=\"field-content\"><img alt=\"\" src=\"http://dusp.mit.edu/sites/dusp.mit.edu/files/styles/profile_pic/public/user/pictures/IMG_3842_cropped_0.jpg?itok=l92zh8uC\"/></div> </div>\n",
      "<div class=\"views-field views-field-name\"> <span class=\"field-content\"><a class=\"username\" href=\"/faculty/mariana-arcaya\" title=\"View user profile.\">Mariana Arcaya</a></span> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-1\"> <div class=\"field-content\">Associate Professor of Urban Planning and Public Health </div> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-2\"> <div class=\"field-content\">Associate Department Head</div> </div>\n",
      "<div class=\"views-field views-field-field-other-division\"> <div class=\"field-content\"></div> </div> </div>]\n"
     ]
    }
   ],
   "source": [
    "people = soup.find_all('div', class_='row-people')\n",
    "pprint(people[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found all elements with, and we can access each element's components using the element class's methods. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"views-row views-row-1 views-row-odd views-row-first row-disc-IDG row-people\">\n",
      "<div> <span><div class=\"bull\"></div></span> </div>\n",
      "<div class=\"views-field views-field-field-user-picture\"> <div class=\"field-content\"><img alt=\"\" src=\"http://dusp.mit.edu/sites/dusp.mit.edu/files/styles/profile_pic/public/user/pictures/cherie.jpg?itok=tqCmbLrz\"/></div> </div>\n",
      "<div class=\"views-field views-field-name\"> <span class=\"field-content\"><a class=\"username\" href=\"/faculty/cherie-abbanat\" title=\"View user profile.\">Cherie Abbanat</a></span> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-1\"> <div class=\"field-content\">Lecturer of International Development and Urban Studies</div> </div>\n",
      "<div class=\"views-field views-field-field-position-and-title-2\"> <div class=\"field-content\"></div> </div>\n",
      "<div class=\"views-field views-field-field-other-division\"> <div class=\"field-content\"></div> </div> </div>\n",
      "'Cherie Abbanat \\n Lecturer of International Development and Urban Studies'\n"
     ]
    }
   ],
   "source": [
    "pprint(people[0])\n",
    "pprint(people[0].get_text().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherie Abbanat /faculty/cherie-abbanat  Lecturer of International Development and Urban Studies       \n",
      "Paul Altidor /faculty/paul-altidor  Visiting Lecturer of International Development and Planning        \n",
      "Mariana Arcaya /faculty/mariana-arcaya  Associate Professor of Urban Planning and Public Health    Associate Department Head    \n"
     ]
    }
   ],
   "source": [
    "for person in people[0:3]:\n",
    "    name_href = person.find('a', class_='username')\n",
    "    name = name_href.get_text()\n",
    "    href = name_href.get('href')\n",
    "    pos_1 = person.find('div', class_='views-field-field-position-and-title-1').get_text()\n",
    "    pos_2 = person.find('div', class_='views-field-field-position-and-title-2').get_text()\n",
    "    other = person.find('div', class_='views-field-field-other-division').get_text()\n",
    "    print(name, href, pos_1, pos_2, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! But it turns out that we can do more - we can use the Python requests module to automatically comb through each faculty member's personal page to get their biography and their Areas of Interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherie Abbanat /faculty/cherie-abbanat  Lecturer of International Development and Urban Studies        \n",
      "\n",
      "Cherie is a lecturer at DUSP and in the Department of Architecture where she has been teaching for over fifteen years. Cherie lectures on policy, non-profit management, post-disaster rebuilding in New Orleans and Haiti, and the need for grassroots initiatives.Â \n",
      "As a practitioner, Cherie joined Haiti Projects Inc., a 501 (c)3 non-profit, in 2013 as its CEO to transform Haiti Projects from a fledgling non-profit into a growing social enterprise. Cherie successfully turned Haiti Projects around financially and the non-profit is ready to grow. Haiti Projects boasts 4 employees in the US and close to 90 employees in Haiti. Haiti Projects operates a women's sewing cooperative, a women's health clinic that focuses on family planning, health and hygiene, and a community library. With support from the Kellogg Foundation, Haiti Projects plans to build a new community multi-purpose center in 2015. Â \n",
      "As a Haitian American, Cherie is passionate about empowering women in Haiti and throughout the world.\n",
      "Cherie has her undergraduate degree in Economics and French from Simmons College and her Masters with a concentration in Environmental Policy and Planning from the Massachusetts Institute of Technology (MCP '97).Â \n",
      " \n",
      "\n",
      "Paul Altidor /faculty/paul-altidor  Visiting Lecturer of International Development and Planning         \n",
      "\n",
      "Paul Getty Altidor was named Ambassador Extraordinary and Plenipotentiary of Haiti to the United States in 2012; he presented his credentials to then-President Barack Obama on May 2.Â  He served in this capacity 2019.\n",
      "Ambassador Altidor spent his early years where he was born in JÃ©rÃ©mie, Haiti. He attended primary school in JÃ©rÃ©mie then studied at the Centre dâEtudes Secondaire in Port au Prince. His family later moved to Boston where he completed his secondary education. Ambassador Altidor received his undergraduate degree from Boston College. He earned an MS degree from MIT in Urban Studies and Planning (2004) and also pursued graduate studies in law and economics in France.Â \n",
      "Ambassador Altidor has an extensive private sector background. As a management consultant, he counseled firms in different countries on corporate governance and responsibility. In the aftermath of the 2010 earthquake, Ambassador Altidor led a team of professors and researchers from the Massachusetts Institute of Technologyâs Community Innovators Lab down to Haiti. At the request of Haitian authorities, the team provided guidance to reconstruction officials on housing policy and financing.\n",
      "Prior to the earthquake in Haiti, Ambassador Altidor worked at the International Finance Corporation (IFC) where he advised governments on infrastructure projects and public-private partnerships. He has also worked for the World Bank. Ambassador Altidor has taught at Ecole SupÃ©rieure Catholique de Droit de JÃ©rÃ©mie (ESCDROJ), a law school in his native town of JÃ©rÃ©mie, and he is a frequent speaker at universities in Haiti and the United States.\n",
      " \n",
      "\n",
      "Mariana Arcaya /faculty/mariana-arcaya  Associate Professor of Urban Planning and Public Health    Associate Department Head     \n",
      "\n",
      "Mariana Arcaya is a social epidemiologist and urban planner whose work explores dynamic relationships between geographic contexts, particularly neighborhoods, and health. Mariana conducts scholarly and policy-relevant research in two main areas: 1) bi-directional relationships between place and health, including how health considerations shape socioeconomic outcomes for individuals and communities, and, 2) applied and translational research on the social determinants of health, particularly health risk factors shaped by urban policy and planning decisions.\n",
      "Prior to coming to MIT in 2015, Mariana served as a post-doctoral fellow at the Harvard Center for Population and Development Studies. She holds a Doctorate of Science from the Harvard School of Public Health, and a Master of City Planning from MIT's Department of Urban Studies & Planning. Her professional work experience includes instituting and managing a Public Health Division within Metropolitan Bostonâs regional planning agency, as well as designing and overseeing the implementation of healthy urban planning strategies under a federally funded Community Transformation Grant.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for person in people[0:3]:\n",
    "    name_href = person.find('a', class_='username')\n",
    "    name = name_href.get_text()\n",
    "    href = name_href.get('href')\n",
    "    pos_1 = person.find('div', class_='views-field-field-position-and-title-1').get_text()\n",
    "    pos_2 = person.find('div', class_='views-field-field-position-and-title-2').get_text()\n",
    "    other = person.find('div', class_='views-field-field-other-division').get_text()\n",
    "    if href:\n",
    "        person_soup = BeautifulSoup(requests.get('http://dusp.mit.edu' + href).content, 'html.parser')\n",
    "        bio = person_soup.find('div', class_='pane-user-field-bio').get_text()\n",
    "    print(name, href, pos_1, pos_2, other, bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherie Abbanat /faculty/cherie-abbanat  Lecturer of International Development and Urban Studies        \n",
      "\n",
      "Cherie is a lecturer at DUSP and in the Department of Architecture where she has been teaching for over fifteen years. Cherie lectures on policy, non-profit management, post-disaster rebuilding in New Orleans and Haiti, and the need for grassroots initiatives.Â \n",
      "As a practitioner, Cherie joined Haiti Projects Inc., a 501 (c)3 non-profit, in 2013 as its CEO to transform Haiti Projects from a fledgling non-profit into a growing social enterprise. Cherie successfully turned Haiti Projects around financially and the non-profit is ready to grow. Haiti Projects boasts 4 employees in the US and close to 90 employees in Haiti. Haiti Projects operates a women's sewing cooperative, a women's health clinic that focuses on family planning, health and hygiene, and a community library. With support from the Kellogg Foundation, Haiti Projects plans to build a new community multi-purpose center in 2015. Â \n",
      "As a Haitian American, Cherie is passionate about empowering women in Haiti and throughout the world.\n",
      "Cherie has her undergraduate degree in Economics and French from Simmons College and her Masters with a concentration in Environmental Policy and Planning from the Massachusetts Institute of Technology (MCP '97).Â \n",
      " \n",
      "  9-520   abbanat@mit.edu  None\n",
      "Paul Altidor /faculty/paul-altidor  Visiting Lecturer of International Development and Planning         \n",
      "\n",
      "Paul Getty Altidor was named Ambassador Extraordinary and Plenipotentiary of Haiti to the United States in 2012; he presented his credentials to then-President Barack Obama on May 2.Â  He served in this capacity 2019.\n",
      "Ambassador Altidor spent his early years where he was born in JÃ©rÃ©mie, Haiti. He attended primary school in JÃ©rÃ©mie then studied at the Centre dâEtudes Secondaire in Port au Prince. His family later moved to Boston where he completed his secondary education. Ambassador Altidor received his undergraduate degree from Boston College. He earned an MS degree from MIT in Urban Studies and Planning (2004) and also pursued graduate studies in law and economics in France.Â \n",
      "Ambassador Altidor has an extensive private sector background. As a management consultant, he counseled firms in different countries on corporate governance and responsibility. In the aftermath of the 2010 earthquake, Ambassador Altidor led a team of professors and researchers from the Massachusetts Institute of Technologyâs Community Innovators Lab down to Haiti. At the request of Haitian authorities, the team provided guidance to reconstruction officials on housing policy and financing.\n",
      "Prior to the earthquake in Haiti, Ambassador Altidor worked at the International Finance Corporation (IFC) where he advised governments on infrastructure projects and public-private partnerships. He has also worked for the World Bank. Ambassador Altidor has taught at Ecole SupÃ©rieure Catholique de Droit de JÃ©rÃ©mie (ESCDROJ), a law school in his native town of JÃ©rÃ©mie, and he is a frequent speaker at universities in Haiti and the United States.\n",
      " \n",
      " None  altidorp@mit.edu  None\n",
      "Mariana Arcaya /faculty/mariana-arcaya  Associate Professor of Urban Planning and Public Health    Associate Department Head     \n",
      "\n",
      "Mariana Arcaya is a social epidemiologist and urban planner whose work explores dynamic relationships between geographic contexts, particularly neighborhoods, and health. Mariana conducts scholarly and policy-relevant research in two main areas: 1) bi-directional relationships between place and health, including how health considerations shape socioeconomic outcomes for individuals and communities, and, 2) applied and translational research on the social determinants of health, particularly health risk factors shaped by urban policy and planning decisions.\n",
      "Prior to coming to MIT in 2015, Mariana served as a post-doctoral fellow at the Harvard Center for Population and Development Studies. She holds a Doctorate of Science from the Harvard School of Public Health, and a Master of City Planning from MIT's Department of Urban Studies & Planning. Her professional work experience includes instituting and managing a Public Health Division within Metropolitan Bostonâs regional planning agency, as well as designing and overseeing the implementation of healthy urban planning strategies under a federally funded Community Transformation Grant.\n",
      " \n",
      "  9-426   marcaya@mit.edu  Community Planning and Economic Development, Environmental Planning and Management, Healthy Communities and Active Living, Urban Information, Technology, and Media and Analytics\n"
     ]
    }
   ],
   "source": [
    "for person in people[0:3]:\n",
    "    name_href = person.find('a', class_='username')\n",
    "    name = name_href.get_text()\n",
    "    href = name_href.get('href')\n",
    "    pos_1 = person.find('div', class_='views-field-field-position-and-title-1').get_text()\n",
    "    pos_2 = person.find('div', class_='views-field-field-position-and-title-2').get_text()\n",
    "    other = person.find('div', class_='views-field-field-other-division').get_text()\n",
    "    if href:\n",
    "        person_soup = BeautifulSoup(requests.get('http://dusp.mit.edu' + href).content, 'html.parser')\n",
    "        bio = person_soup.find('div', class_='pane-user-field-bio')\n",
    "        if bio:\n",
    "            bio = bio.get_text()\n",
    "        office = person_soup.find('div', class_='views-field views-field-field-office')\n",
    "        if office:\n",
    "            office = office.get_text()\n",
    "        email = person_soup.find('div', class_='views-field views-field-field-secondary-email')\n",
    "        if email:\n",
    "            email = email.get_text()\n",
    "        interests = person_soup.find('strong', class_='views-label views-label-field-areas-of-interest')\n",
    "        if interests:\n",
    "            interests = interests.next_sibling.next_sibling.get_text()\n",
    "    print(name, href, pos_1, pos_2, other, bio, office, email, interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "output_csv = 'faculty.csv'\n",
    "\n",
    "with open(output_csv, 'w') as f:\n",
    "    field_names = ['name', 'href', 'pos_1', 'pos_2', 'other_affil', 'bio', 'office', 'email', 'interests']\n",
    "    writer = csv.DictWriter(f, field_names)\n",
    "    writer.writeheader()\n",
    "    for person in people[0:3]:\n",
    "        name_href = person.find('a', class_='username')\n",
    "        name = name_href.get_text()\n",
    "        href = 'http://dusp.mit.edu' + name_href.get('href')\n",
    "        pos_1 = person.find('div', class_='views-field-field-position-and-title-1').get_text()\n",
    "        pos_2 = person.find('div', class_='views-field-field-position-and-title-2').get_text()\n",
    "        other_affil = person.find('div', class_='views-field-field-other-division').get_text()\n",
    "        if href:\n",
    "            person_soup = BeautifulSoup(requests.get(href).content, 'html.parser')\n",
    "            bio = person_soup.find('div', class_='pane-user-field-bio')\n",
    "            if bio:\n",
    "                bio = bio.get_text()\n",
    "            office = person_soup.find('div', class_='views-field views-field-field-office')\n",
    "            if office:\n",
    "                office = office.get_text()\n",
    "            email = person_soup.find('div', class_='views-field views-field-field-secondary-email')\n",
    "            if email:\n",
    "                email = email.get_text()\n",
    "            interests = person_soup.find('strong', class_='views-label views-label-field-areas-of-interest')\n",
    "            if interests:\n",
    "                interests = interests.next_sibling.next_sibling.get_text()\n",
    "        row = {\n",
    "            'name': name,\n",
    "            'href': href,\n",
    "            'pos_1': pos_1,\n",
    "            'pos_2': pos_2,\n",
    "            'other_affil': other_affil,\n",
    "            'bio': bio,\n",
    "            'office': office,\n",
    "            'email': email,\n",
    "            'interests': interests\n",
    "        }\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Cherie Abbanat...\n",
      "Scraping Paul Altidor...\n",
      "Scraping Mariana Arcaya...\n",
      "Scraping Nicholas Ashford...\n",
      "Scraping Lawrence S. Bacow...\n",
      "Scraping Eran Ben-Joseph...\n",
      "Scraping Alan Berger...\n",
      "Scraping Devin Michelle Bunten...\n",
      "Scraping Gabriella Carolini...\n",
      "Scraping Phillip Clay...\n",
      "Scraping Joseph Coughlin...\n",
      "Scraping Karilyn Crockett...\n",
      "Scraping Dayna Cunningham...\n",
      "Scraping Alexander D'Hooghe...\n",
      "Scraping Catherine D'Ignazio...\n",
      "Scraping Mary Jane Daly...\n",
      "Scraping Michael Dennis...\n",
      "Scraping Fabio Duarte...\n",
      "Scraping Louise Elving...\n",
      "Scraping John E. FernÃ¡ndez...\n",
      "Scraping Joseph Ferreira...\n",
      "Scraping Robert Fogelson...\n",
      "Scraping Dennis Frenchman...\n",
      "Scraping Ralph Gakenheimer...\n",
      "Scraping David Geltner...\n",
      "Scraping Amy Glasmeier...\n",
      "Scraping Ezra Haber Glenn...\n",
      "Scraping Gary Hack...\n",
      "Scraping David Hsu...\n",
      "Scraping Eric Huntley...\n",
      "Scraping Jason Jackson...\n",
      "Scraping Erica Caple James...\n",
      "Scraping Langley Keyes...\n",
      "Scraping Melvin King...\n",
      "Scraping Eric Klopfer...\n",
      "Scraping Janelle Knox-Hayes...\n",
      "Scraping Takeo Kuwabara...\n",
      "Scraping Yuan Lai...\n",
      "Scraping Marie Law Adams...\n",
      "Scraping Tunney Lee...\n",
      "Scraping Jeff Levine...\n",
      "Scraping Frank Levy...\n",
      "Scraping Jennifer Light...\n",
      "Scraping Miho Mazereeuw...\n",
      "Scraping Ceasar McDowell...\n",
      "Scraping Tod McGrath...\n",
      "Scraping Julie Newman...\n",
      "Scraping Mary Anne Ocampo...\n",
      "Scraping Paul Osterman...\n",
      "Scraping Karen R. Polenske...\n",
      "Scraping Balakrishnan Rajagopal...\n",
      "Scraping Carlo Ratti...\n",
      "Scraping Elisabeth Reynolds...\n",
      "Scraping Peter Roth...\n",
      "Scraping Brent D. Ryan...\n",
      "Scraping Albert Saiz...\n",
      "Scraping Frederick Salvucci...\n",
      "Scraping AdÃ¨le NaudÃ© Santos...\n",
      "Scraping Bish Sanyal...\n",
      "Scraping Hashim Sarkis...\n",
      "Scraping Otto Scharmer...\n",
      "Scraping Rafi Segal...\n",
      "Scraping Andres Sevtsuk...\n",
      "Scraping Kairos Shen...\n",
      "Scraping Bob Simha...\n",
      "Scraping Amy Smith...\n",
      "Scraping Anne Whiston Spirn...\n",
      "Scraping Justin Steil...\n",
      "Scraping Anson Stewart...\n",
      "Scraping Jonah Susskind...\n",
      "Scraping Lawrence Susskind...\n",
      "Scraping Terry Szold...\n",
      "Scraping Zhengzhen Tan...\n",
      "Scraping J. Phillip Thompson...\n",
      "Scraping Lawrence Vale...\n",
      "Scraping Bruno Verdini...\n",
      "Scraping Delia Wendel...\n",
      "Scraping James Wescoat...\n",
      "Scraping William Wheaton...\n",
      "Scraping Clarence Williams...\n",
      "Scraping Sarah Williams...\n",
      "Scraping P. Christopher Zegras...\n",
      "Scraping Jinhua Zhao...\n",
      "Scraping Siqi Zheng...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import wget\n",
    "import time\n",
    "\n",
    "output_csv = 'faculty.csv'\n",
    "\n",
    "with open(output_csv, 'w') as f:\n",
    "    field_names = ['name', 'href', 'pos_1', 'pos_2', 'other_affil', \n",
    "                   'bio', 'office', 'email', 'interests', 'image_file']\n",
    "    writer = csv.DictWriter(f, field_names)\n",
    "    writer.writeheader()\n",
    "    for person in people:\n",
    "        name_href = person.find('a', class_='username')\n",
    "        name = name_href.get_text()\n",
    "        print(f'Scraping {name}...')\n",
    "        href = 'http://dusp.mit.edu' + name_href.get('href')\n",
    "        image_url = person.find('img')\n",
    "        if image_url:\n",
    "            image_url = image_url.get('src')\n",
    "            out_dir = os.getcwd() + '/images/'\n",
    "            image_file = name.replace(' ', '_').lower().replace('.', '') + '.jpg'\n",
    "            try:\n",
    "                wget.download(image_url, out_dir + image_file)\n",
    "            except Exception as err: \n",
    "                print(err + '---Could not download faculty photo.')\n",
    "                image_file = err\n",
    "        pos_1 = person.find('div', class_='views-field-field-position-and-title-1').get_text()\n",
    "        pos_2 = person.find('div', class_='views-field-field-position-and-title-2').get_text()\n",
    "        other_affil = person.find('div', class_='views-field-field-other-division').get_text()\n",
    "        if href:\n",
    "            person_soup = BeautifulSoup(requests.get(href).content, 'html.parser')\n",
    "            bio = person_soup.find('div', class_='pane-user-field-bio')\n",
    "            if bio:\n",
    "                bio = bio.get_text()\n",
    "            office = person_soup.find('div', class_='views-field views-field-field-office')\n",
    "            if office:\n",
    "                office = office.get_text()\n",
    "            email = person_soup.find('div', class_='views-field views-field-field-secondary-email')\n",
    "            if email:\n",
    "                email = email.get_text()\n",
    "            interests = person_soup.find('strong', class_='views-label views-label-field-areas-of-interest')\n",
    "            if interests:\n",
    "                interests = interests.next_sibling.next_sibling.get_text()\n",
    "        row = {\n",
    "            'name': name,\n",
    "            'href': href,\n",
    "            'pos_1': pos_1,\n",
    "            'pos_2': pos_2,\n",
    "            'other_affil': other_affil,\n",
    "            'bio': bio,\n",
    "            'office': office,\n",
    "            'email': email,\n",
    "            'interests': interests,\n",
    "            'image_file': image_file\n",
    "        }\n",
    "        writer.writerow(row)\n",
    "        time.sleep(1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
